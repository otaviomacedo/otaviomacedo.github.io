---
layout: post
title:  "Books in a steady state"
date:   2021-03-20 19:53:00 +0000
categories: linear-algebra
---

A library is about to open in your town. Based on data collected from other libraries of about the same size and type, we should expect the following traffic pattern, expressed in probabilities: on any given day, every book has a 12% probability of being borrowed by some customer. And books that are on users' hands have a 36% chance of being returned.

Libraries, of course, are always in flux; every day, a certain set of books is borrowed by users and another set is returned to the library. So, a natural question to ask is: assuming that these probabilities remain constant, what will happen over time? Is the number of books in the library going to fluctuate, making the library almost empty at times and very full at others? Or is it going to reach a steady state, in which the number of books remain relatively constant (even though the individual books in the library change all the time)? And, if the answer is the latter, what will that steady state be? The answer to these questions may help the librarian make some decisions on whether to purchase more books or how to allocate space in the library, for example.

Before trying to solve this problem, let's build up some intuition using diagrams. Suppose the stock of this library consists of 20,000 books. On day 0 (before it opens up to the public), all books are in the library and therefore none is being held by users.


![Day 0 of the library](/assets/lib-markov-day0.png)

The blue shaded circle represents the set of avilable books and the orange shaded one represents the set of borrowed books. The edges are the propotion of each set that is expected to move to the other set on any given day. 

On day 1, according to the expected values of these probabilities, 2400 books will leave the library to be held by users. Since no user was holding any books on the previous day, no book was returned.

![Day 1 of the library](/assets/lib-markov-day1.png)

On day 2, we should expect that 2112 books will move from the library to users, while 864 books will make the trip the other way around:

![Day 2 of the library](/assets/lib-markov-day2.png)

We can model this mathematically using a system of linear equations:

$$
\begin{align}
a_{i + 1} & = 0.88a_i + 0.36b_i \\
b_{i + 1} & = 0.12a_i + 0.64b_i 
\end{align}
$$

where $$a_i$$ and $$b_i$$ are the number of books available and borrowed, respectively, on day $$i$$. And, of course, when dealing with systems of linear equations, it's more convenient to use matrix notation:

$$
d_{i + 1} = \begin{bmatrix}0.88 & 0.36\\ 0.12 & 0.64\end{bmatrix}d_i
$$

with $$d_0 = \begin{bmatrix}20000\\0\end{bmatrix}$$ and, thus, $$d_1 = \begin{bmatrix}17600\\2400\end{bmatrix}$$, $$d_2 = \begin{bmatrix}16352\\3648\end{bmatrix}$$ and so on.

With the mathematical model in place, we can now try to answer the question. One way to do this is by crunching the numbers and projecting the behavior of the system into the future. So, let's start with $$d_0$$ and repeat this matrix multiplication a few more times to see what happens:

![Number of books available and borrowed over time](/assets/lib-convergence.svg)

We can see that, by day 7, the system did reach a steady state, with the number of available books is 15,000. The graph ends at day 24, which, for practical purposes, is our "infinity"; the state of the system will remain the same arbitrarily into the future after day 24.

If you've read the [previous post][1], in which we were trying to find how many different paths exist between any two points in a city, you'll see that the approach I used there is very similar to what I'm doing here: take a matrix that represents your system and multiply that matrix by the vector that represents the initial condition. Then multiply the matrix again by the result and so on.

This is a straightforward, but naive, approach to solve these types of problems. It works when the number of iterations is small (for example, just 5 iterations in the case of the path counting problem) or the matrix is small (2 by 2 in the library problem), or both. In larger systems, this is simply too expensive a computation to carry out. So, we need to find a smarter way. And, to do this, we need to explore some important but not obvious properties of our model.

## Linear combinations (change this title)

Although multiplying the matrix repeatedly is inefficent and, ultimately, not what we want to do, let's explore what would happen if we did do this. We saw that 24 iterations is more than enough for the library to reach a steady state. On day 24, we will have done 24 multiplications:

$$\mathbf{d_{24}} = \underbrace{P\ldots P}_{24\rm\ times}\mathbf{d_0}$$

Matrix multiplication is associative, which means we can group the multiplications however we want. In other words, $$P(P(\mathbf{d_0})) = P^2\mathbf{d_0}$$

$$P^{24} = \begin{bmatrix}0.75 & 0.75 \\ 0.25 & 0.25\end{bmatrix}$$

We can multiply this matrix by whatever vector we want to obtain another vector. For example, we could do:

$$
P^{24}\begin{bmatrix}10 \\ 6\end{bmatrix} = 
\begin{bmatrix}12\\ 4\end{bmatrix}
$$

to represent an alternative scenario in which there were 10 books available and 6 borrowed and ended up with 12 and 4, respectively, at the next step. But, instead of 10 and 6, consider these two other vectors:

$$
\mathbf{v_1} = \begin{bmatrix}3\\ 1\end{bmatrix}
\qquad
\mathbf{v_2} = \begin{bmatrix}1\\ -1\end{bmatrix}
$$

You can check for yourself that:

$$
P^{24}\mathbf{v_1} = \mathbf{v_1}
\qquad
P^{24}\mathbf{v_2} = \begin{bmatrix}0\\ 0\end{bmatrix}
$$


There is something going on here. In the first multiplication, we are multiplying the matrix by a vector and getting the same vector back. In the second one, we are multiplying the matrix by another vector and getting the zero vector. In some sense, $$\mathbf{v_1}$$ and $$\mathbf{v_2}$$ are special. In fact, $$\mathbf{v_1}$$ is even more special, because $$P^n\mathbf{v_1} = \mathbf{v_1}$$ for any positive $$n$$.

Ok, this is _mildly interesting_... so what?

Remember that what we actually want to do is to find the value of $$P^{24}\mathbf{d_0}$$ (that is, the value we get if we start at day 0 and change the system day by day until we reach day 24 &mdash; or any other day after that). Here comes the trick: we can represent $$\mathbf{d_0}$$ in terms of $$\mathbf{v_1}$$ and $$\mathbf{v_2}$$:

$$
\mathbf{d_0} =
500\begin{bmatrix}3\\ 1\end{bmatrix}
-500\begin{bmatrix}-1\\ 1\end{bmatrix}
$$

which is known in the trade as a **linear combination**. 

Then, multiplying $$P^{24}$$ on the left on both sides, we get:


$$
P^{24}\mathbf{d_0} = P^{24}
\left(
    500\begin{bmatrix}3\\ 1\end{bmatrix}
    -500\begin{bmatrix}-1\\ 1\end{bmatrix}
\right)
$$

Just like with numbers, when we multiply a matrix by a sum of other matrices, we can "move" the outer matrix inside the parentheses (the **distributive property**):

$$
P^{24}\mathbf{d_0} = 
    500.P^{24}\begin{bmatrix}3\\ 1\end{bmatrix}
    -500.P^{24}\begin{bmatrix}-1\\ 1\end{bmatrix}
$$

which simplifies to:

$$
P^{24}\mathbf{d_0} = 500\begin{bmatrix}3\\ 1\end{bmatrix}
$$

which is exactly the first term of the linear combination that produces $$\mathbf{d_0}$$. And, if you actually compute this multiplication, you'll see that it matches the steady state we achieved by repeated multiplications.

Long story short: if you can find these special vectors (especially $$\mathbf{v_1}$$), all you need to compute the steady state is to throw away all the other terms in the linear combination that gives you the initial state. The takeaway here is that, no matter how many steps it would take to reach the steady state, you can compute it with only a few matrix multiplications.

<!-- Third narrative sub-arc: eigenvalues and eigenvectors -->

## Eigenvalues and eigenvectors (change this title)

We've been talking about these special vectors, but, to go deeper, we need to define them more precisely. Suppose if you have a matrix $$A$$. You may able to find a vector $$\mathbf{x}$$, such that multiplying $$A$$ by $$\mathbf{x}$$ is equivalent to just scale $$\mathbf{x}$$ by some number $$\lambda$$. More succintly:

$$A\mathbf{x} = \lambda\mathbf{x}$$

And there may exist many such pairs consisting of a vector and a number that satisfy this equation, for a given matrix. The right name for this special type of vector is **eigenvector**. And the accompanying number $$\lambda$$ is rightly called **eigenvalue**. 

In the example above, the matrix $$P$$ has two eigenvectors: $$\mathbf{v_1}$$ and $$\mathbf{v_2}$$; their respective eigenvalues are 1 and 0.52. These numbers are what allowed us to reach such a highly simplified solution. To see why, let's blablablabal

We know that

$$P\mathbf{v_1} = 1.\mathbf{v_1}$$

which implies that

$$PP\mathbf{v_1} = 1.P\mathbf{v_1}$$

but the right hand side is just $$\mathbf{v_1}$$, so

$$P^2\mathbf{v_1} = 1^2.\mathbf{v_1}$$

We can repeat this as many times as we want, and we will conclude that

$$P^n\mathbf{v_1} = \mathbf{v_1}$$

for any $$n > 0$$.

A similar reasoning applies to $$\mathbf{v_2}$$, but in this case, we will have $$P^n = 0.52^n\mathbf{v_2}$$. As $$n$$ gets larger, $$0.52^n$$ approaches 0. Putting these two facts together and applying to our example, we get:

$$
\begin{align}
P^{24}\mathbf{d_0} & = 500.1^{24}\mathbf{v_1} - 500.(0.52)^{24}\mathbf{v_2}\\[0.6ex]
& = 500\mathbf{v_1} - 0\mathbf{v_2}\\[0.6ex]
& = 500\mathbf{v_1}
\end{align}
$$

And it's easy to see why increasing the exponent beyond this point (that is, moving further ahead in time in our model) doesn't change anything. We have already reached a steady state.

What about other matrices? I mean, it's neat that in this example one of the eigenvalues was 1 and the other was a number between 0 and 1. But if we started with other probabilities, perhaps we wouldn't be so lucky? Well, it turns out that we would. In any matrix where all columns add up to 1 (otherwise known as a **Markov matrix**), exactly one eigenvalue is equal to 1 and all the others will be between 0 and 1 (its absolute value, to be more precise).

This is reassuring, but still leaves an unsolved problem: how to find the eigenvectors? At the very least, we need to find the eigenvector that pairs up with the eigenvalue 1.

## Computing the eigens (change this title)

To compute the eigenvalues and eigenvectors of a matrix, let's look again at the equation that defines them:

$$A\mathbf{x} = \lambda\mathbf{x}$$

Rearranging the terms, we get

$$A\mathbf{x} - \lambda\mathbf{x} = \mathbf{0}$$

And, finally,

$$(A - \lambda I)\mathbf{x} = \mathbf{0}$$

where $$I$$ is the **identity matrix**, that is, the matrix where all elements of the diagonal are 1 and the rest are 0. Now, to go further, we need to appeal to the concept of **[determinant]** of a matrix. In the case of a 2 by 2 matrix

$$
A = \begin{bmatrix}
a & b \\
c & d \\
\end{bmatrix}
$$

the determinant is easy to express and compute: 

$$\det A = ad - bc$$

And, in particular, 

$$
\begin{align}
\det (A -\lambda I) & = (a -\lambda)(d - \lambda) - bc\\
& = ad 
\end{align}
$$

If we are to have any eigenvector other than $$\mathbf{0}$$, the determinant of $$A -\lambda I$$ must be 0

[1]: https://otaviomacedo.github.io/graph-theory/2021/03/07/paths.html
[determinant]: https://en.wikipedia.org/wiki/Determinant